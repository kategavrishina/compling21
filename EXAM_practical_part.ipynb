{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c07bc76a",
      "metadata": {
        "id": "c07bc76a"
      },
      "source": [
        "## Задание 1\n",
        "\n",
        "Опеределите части речи слов в этом тексте, используя пайморфи. В форму запишите слова, которым приписан тэг VERB. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9a246979",
      "metadata": {
        "id": "9a246979"
      },
      "outputs": [],
      "source": [
        "text = \"Зонды будут запущены в космос в 2029 году и отправятся ко второй точке Лагранжа в системе Солнце\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pymorphy2"
      ],
      "metadata": {
        "id": "rviyTBXNk3PA",
        "outputId": "29ed896a-be80-4825-b629-38e4affa7106",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 9.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ]
        }
      ],
      "id": "rviyTBXNk3PA"
    },
    {
      "cell_type": "code",
      "source": [
        "import pymorphy2"
      ],
      "metadata": {
        "id": "RMVFMcCOk_Cd"
      },
      "execution_count": 9,
      "outputs": [],
      "id": "RMVFMcCOk_Cd"
    },
    {
      "cell_type": "code",
      "source": [
        "morph = pymorphy2.MorphAnalyzer()"
      ],
      "metadata": {
        "id": "6XtLQwqOk7t0"
      },
      "execution_count": 10,
      "outputs": [],
      "id": "6XtLQwqOk7t0"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b6c7d837",
      "metadata": {
        "id": "b6c7d837",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "44ff2bac-70e6-48a2-e5c0-45134fc79c6f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'будут, отправятся'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "', '.join([w for w in text.split() if 'VERB' in morph.parse(w)[0].tag])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[morph.parse(w)[0].tag for w in text.split()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVxuqZz7_Hpi",
        "outputId": "22c4699d-4c90-4510-c4dc-6d8b21b5b92e"
      },
      "id": "mVxuqZz7_Hpi",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[OpencorporaTag('NOUN,inan,masc plur,nomn'),\n",
              " OpencorporaTag('VERB,impf,intr plur,3per,futr,indc'),\n",
              " OpencorporaTag('PRTS,perf,past,pssv plur'),\n",
              " OpencorporaTag('PREP'),\n",
              " OpencorporaTag('NOUN,inan,masc sing,accs'),\n",
              " OpencorporaTag('PREP'),\n",
              " OpencorporaTag('NUMB,intg'),\n",
              " OpencorporaTag('NOUN,inan,masc sing,loc2'),\n",
              " OpencorporaTag('CONJ'),\n",
              " OpencorporaTag('VERB,perf,intr plur,3per,futr,indc'),\n",
              " OpencorporaTag('PREP Vpre'),\n",
              " OpencorporaTag('ADJF,Anum femn,sing,gent'),\n",
              " OpencorporaTag('NOUN,inan,femn sing,loct'),\n",
              " OpencorporaTag('NOUN,inan,masc sing,gent'),\n",
              " OpencorporaTag('PREP'),\n",
              " OpencorporaTag('NOUN,inan,femn sing,loct'),\n",
              " OpencorporaTag('NOUN,inan,neut sing,nomn')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9beed7ea",
      "metadata": {
        "id": "9beed7ea"
      },
      "source": [
        "## Задание 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4cb5a6f",
      "metadata": {
        "id": "f4cb5a6f"
      },
      "source": [
        "На данных предложениях обучите TFIDF векторайзер из sklearn (с дефолтными параметрами). Найдите слово с самым высоким коэффициентом tfidf в первом тексте. Вставьте его в форму."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "0b04a4ec",
      "metadata": {
        "id": "0b04a4ec"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "r = requests.get(\n",
        "    'https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/anna_karenina.txt'\n",
        ")\n",
        "\n",
        "# работайте с этими предложениями\n",
        "sentences = r.text.split('\\n')\n",
        "sentences = [sent for sent in sentences if len(sent) > 10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "29f09ed1",
      "metadata": {
        "id": "29f09ed1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a19e0b0-5ed8-47ef-a0fe-855a032f4fe6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['«Анна Каренина» – это сложное, психологически утонченное, остропроблемное произведение, насыщенное приметами времени. Л.Н. Толстой на страницах произведения показывает, как рушатся остатки патриархального уклада жизни в России под натиском буржуазного прогресса, как падают нравы, ослабевают семейные устои, вырождается аристократия.',\n",
              " 'Роман во многом автобиографичен. Работая над ним, Толстой уяснял взгляд на современность и свою собственную жизнь.',\n",
              " 'Лев Николаевич Толстой',\n",
              " 'ЧАСТЬ ПЕРВАЯ',\n",
              " 'ЧАСТЬ ВТОРАЯ']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "sentences[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "gwvasLxr_ukV"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "id": "gwvasLxr_ukV"
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform([sent for sent in sentences if sent != ''])"
      ],
      "metadata": {
        "id": "2GgsQXmvnA6d"
      },
      "execution_count": 20,
      "outputs": [],
      "id": "2GgsQXmvnA6d"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "558f285c",
      "metadata": {
        "id": "558f285c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dd6c4fd-61e1-4c3b-88c8-b0eeed58e169"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7536, 33241)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpa1_nVQAjsJ",
        "outputId": "cbef1907-ea9c-4d0d-897c-c3d06f444250"
      },
      "id": "hpa1_nVQAjsJ",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7536"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "VV2D4_rCBedJ"
      },
      "id": "VV2D4_rCBedJ",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(X.toarray(), columns = vectorizer.get_feature_names())\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "lURG5dCEBdwn",
        "outputId": "7b38fd91-cb13-4185-a2c2-324aedefd17f"
      },
      "id": "lURG5dCEBdwn",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    11  17015   18  18308  1863  1864   28   30   36  6лизкий  ...  яшвина  \\\n",
              "0  0.0    0.0  0.0    0.0   0.0   0.0  0.0  0.0  0.0      0.0  ...     0.0   \n",
              "1  0.0    0.0  0.0    0.0   0.0   0.0  0.0  0.0  0.0      0.0  ...     0.0   \n",
              "2  0.0    0.0  0.0    0.0   0.0   0.0  0.0  0.0  0.0      0.0  ...     0.0   \n",
              "3  0.0    0.0  0.0    0.0   0.0   0.0  0.0  0.0  0.0      0.0  ...     0.0   \n",
              "4  0.0    0.0  0.0    0.0   0.0   0.0  0.0  0.0  0.0      0.0  ...     0.0   \n",
              "\n",
              "   яшвине  яшвину  яшвиным  ящик  ящика  ящиками  ящике  ящиком  ящику  \n",
              "0     0.0     0.0      0.0   0.0    0.0      0.0    0.0     0.0    0.0  \n",
              "1     0.0     0.0      0.0   0.0    0.0      0.0    0.0     0.0    0.0  \n",
              "2     0.0     0.0      0.0   0.0    0.0      0.0    0.0     0.0    0.0  \n",
              "3     0.0     0.0      0.0   0.0    0.0      0.0    0.0     0.0    0.0  \n",
              "4     0.0     0.0      0.0   0.0    0.0      0.0    0.0     0.0    0.0  \n",
              "\n",
              "[5 rows x 33241 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9abe960c-8b3a-4951-b60a-3e90468d9e6e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>11</th>\n",
              "      <th>17015</th>\n",
              "      <th>18</th>\n",
              "      <th>18308</th>\n",
              "      <th>1863</th>\n",
              "      <th>1864</th>\n",
              "      <th>28</th>\n",
              "      <th>30</th>\n",
              "      <th>36</th>\n",
              "      <th>6лизкий</th>\n",
              "      <th>...</th>\n",
              "      <th>яшвина</th>\n",
              "      <th>яшвине</th>\n",
              "      <th>яшвину</th>\n",
              "      <th>яшвиным</th>\n",
              "      <th>ящик</th>\n",
              "      <th>ящика</th>\n",
              "      <th>ящиками</th>\n",
              "      <th>ящике</th>\n",
              "      <th>ящиком</th>\n",
              "      <th>ящику</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33241 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9abe960c-8b3a-4951-b60a-3e90468d9e6e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9abe960c-8b3a-4951-b60a-3e90468d9e6e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9abe960c-8b3a-4951-b60a-3e90468d9e6e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-1tVlj-Bmc8",
        "outputId": "f053c50b-4942-4139-f0dd-9031c041871e"
      },
      "id": "g-1tVlj-Bmc8",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7536, 33241)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[0].sort_values().index[-5:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxgJL_FOBo1q",
        "outputId": "1a3cade7-f8ff-428e-f90c-0f4e94527721"
      },
      "id": "fxgJL_FOBo1q",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ослабевают', 'психологически', 'приметами', 'насыщенное', 'устои'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[0].sort_values()[-15:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3kErCMkCoHy",
        "outputId": "aef6f0b7-9371-4be1-a2cc-e3ee79e242d4"
      },
      "id": "e3kErCMkCoHy",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "рушатся            0.196715\n",
              "нравы              0.196715\n",
              "натиском           0.196715\n",
              "вырождается        0.196715\n",
              "буржуазного        0.196715\n",
              "уклада             0.196715\n",
              "падают             0.196715\n",
              "патриархального    0.196715\n",
              "страницах          0.196715\n",
              "остропроблемное    0.196715\n",
              "ослабевают         0.196715\n",
              "психологически     0.196715\n",
              "приметами          0.196715\n",
              "насыщенное         0.196715\n",
              "устои              0.196715\n",
              "Name: 0, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfb2e707",
      "metadata": {
        "id": "bfb2e707"
      },
      "source": [
        "## Задание 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea9c6808",
      "metadata": {
        "id": "ea9c6808"
      },
      "source": [
        "Токенизируйте текст Анны Карениной с помощью библиотеки раздел, привидите все к нижнему регистру. Рассчитайте статистики биграммов и униграммов. Найдите наиболее вероятное продолжение \"красный ...\". Вставьте наиболее веротяное следующее слово в форму."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip3 install razdel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isbcm3WsCsff",
        "outputId": "b0350832-2f49-41f3-a20b-4ca878286d39"
      },
      "id": "isbcm3WsCsff",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting razdel\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: razdel\n",
            "Successfully installed razdel-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "21bda476",
      "metadata": {
        "id": "21bda476"
      },
      "outputs": [],
      "source": [
        "import razdel\n",
        "import gensim\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "27d9dd44",
      "metadata": {
        "id": "27d9dd44"
      },
      "outputs": [],
      "source": [
        "tokenized = []\n",
        "for sent in sentences:\n",
        "    tok_sent = [token.text.lower() for token in list(razdel.tokenize(sent))]\n",
        "    tokenized.append(tok_sent)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize"
      ],
      "metadata": {
        "id": "uqXCYeJbU9V4"
      },
      "id": "uqXCYeJbU9V4",
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ngrammer(tokens, n=2):\n",
        "    ngrams = []\n",
        "    for i in range(0,len(tokens)-n+1):\n",
        "        ngrams.append(' '.join(tokens[i:i+n]))\n",
        "    return ngrams"
      ],
      "metadata": {
        "id": "3LK5sIOpC5yf"
      },
      "id": "3LK5sIOpC5yf",
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unigrams = Counter()\n",
        "bigrams = Counter()\n",
        "\n",
        "for sentence in tokenized:\n",
        "    unigrams.update(sentence)\n",
        "    bigrams.update(ngrammer(sentence))"
      ],
      "metadata": {
        "id": "_xPf4cGLC9f-"
      },
      "id": "_xPf4cGLC9f-",
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix = np.zeros((len(unigrams), \n",
        "                   len(unigrams)))\n",
        "id2word = list(unigrams)\n",
        "word2id = {word:i for i, word in enumerate(id2word)}\n",
        "\n",
        "\n",
        "for ngram in bigrams:\n",
        "    word1, word2 = ngram.split()\n",
        "    matrix[word2id[word1]][word2id[word2]] =  (bigrams[ngram]/unigrams[word1])"
      ],
      "metadata": {
        "id": "NLxahuV_V0Cd"
      },
      "id": "NLxahuV_V0Cd",
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "current_idx = word2id['красный']\n",
        "\n",
        "chosen = matrix[current_idx].argmax()\n",
        "id2word[chosen]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "81DbWlTtWySx",
        "outputId": "14e66545-eb73-4b67-fa94-99ba36940f54"
      },
      "id": "81DbWlTtWySx",
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'мешочек'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "677afdf3",
      "metadata": {
        "id": "677afdf3"
      },
      "source": [
        "## Задание 4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbbce216",
      "metadata": {
        "id": "fbbce216"
      },
      "source": [
        "Расчитайте ненормализованное растояние Дамерау-Левенштейна и ненормализованное растояние Левенштейна между этими словами (каждое с каждым), найдите пару слов, для которых эти расстояния отличаются. Вставьте эти слова в форму"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "4c37226f",
      "metadata": {
        "id": "4c37226f"
      },
      "outputs": [],
      "source": [
        "words = [\"решение\",\"ршеение\",\"ренешик\",\"рещиние\",\"ришение\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textdistance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYDcuejxxgpa",
        "outputId": "f8c6d0c0-2f43-4b14-a99d-837855ccbe48"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting textdistance\n",
            "  Downloading textdistance-4.2.2-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: textdistance\n",
            "Successfully installed textdistance-4.2.2\n"
          ]
        }
      ],
      "id": "AYDcuejxxgpa"
    },
    {
      "cell_type": "code",
      "source": [
        "import textdistance"
      ],
      "metadata": {
        "id": "OwCkbA29xhjs"
      },
      "execution_count": 65,
      "outputs": [],
      "id": "OwCkbA29xhjs"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "10f1d01e"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ],
      "id": "10f1d01e"
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter"
      ],
      "metadata": {
        "id": "KRYdzmEYx19T"
      },
      "execution_count": 67,
      "outputs": [],
      "id": "KRYdzmEYx19T"
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "de505b50"
      },
      "outputs": [],
      "source": [
        "dists = np.zeros((5, 5))\n",
        "\n",
        "for i, word1 in enumerate(words):\n",
        "    for j, word2  in enumerate(words):\n",
        "        dists[i][j] = textdistance.damerau_levenshtein.distance(word1, word2)"
      ],
      "id": "de505b50"
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "582c5e91",
      "metadata": {
        "id": "582c5e91"
      },
      "outputs": [],
      "source": [
        "dists2 = np.zeros((5, 5))\n",
        "\n",
        "for i, word1 in enumerate(words):\n",
        "    for j, word2  in enumerate(words):\n",
        "        dists2[i][j] = textdistance.levenshtein.distance(word1, word2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dists == dists2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-YHBdw1E9bg",
        "outputId": "37c8ffb0-1b9e-4032-89ee-9e7a6ef59350"
      },
      "id": "B-YHBdw1E9bg",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True, False,  True,  True,  True],\n",
              "       [False,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True]])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d7dff1d",
      "metadata": {
        "id": "3d7dff1d"
      },
      "source": [
        "## Задание 5\n",
        "\n",
        "Загрузите токенизатор distilbert-base-uncased из huggingface. Токенизируйте предложения из Анны Карениной с помощью предобученного токенизатора и обучите Fastext модель со следующими параметрами: cbow, размер вектора 300, размер окна 5, минимальный размер символьного нграмма - 2, максимальный размер символьного нграмма - 7. Найдите ближайшее слово к слову \"каренина\", вставьте его в форму."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install transformers"
      ],
      "metadata": {
        "id": "Eulp37M8zc9V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "360e5d13-3cbe-4ee0-a08e-35e0b287371a"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 42.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 12.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 44.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.20.1\n"
          ]
        }
      ],
      "id": "Eulp37M8zc9V"
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "f68b6421"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer"
      ],
      "id": "f68b6421"
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')"
      ],
      "metadata": {
        "id": "c-_hre5Czbbg"
      },
      "execution_count": 99,
      "outputs": [],
      "id": "c-_hre5Czbbg"
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens = [tokenizer.tokenize(sent) for sent in sentences]"
      ],
      "metadata": {
        "id": "eBILRUeWGQ-b"
      },
      "id": "eBILRUeWGQ-b",
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens[0][:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1rGbCx2QOrp",
        "outputId": "3f9e42ce-7bbf-4f71-f94b-342965d15696"
      },
      "id": "B1rGbCx2QOrp",
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['«',\n",
              " 'а',\n",
              " '##н',\n",
              " '##на',\n",
              " 'к',\n",
              " '##а',\n",
              " '##р',\n",
              " '##е',\n",
              " '##н',\n",
              " '##и',\n",
              " '##на',\n",
              " '»',\n",
              " '–',\n",
              " 'э',\n",
              " '##т',\n",
              " '##о',\n",
              " 'с',\n",
              " '##л',\n",
              " '##о',\n",
              " '##ж']"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fasttext = gensim.models.FastText(all_tokens, sg=0, size=300, window=5, min_n=2, max_n=7)"
      ],
      "metadata": {
        "id": "CRLH_4OIGBYN"
      },
      "id": "CRLH_4OIGBYN",
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fasttext.most_similar('каренина')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b56Y0ffMGudH",
        "outputId": "15829417-c803-4ec9-834e-57aec45d0688"
      },
      "id": "b56Y0ffMGudH",
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('##на', 0.6607786417007446),\n",
              " ('##ка', 0.5585423111915588),\n",
              " ('landau', 0.42687708139419556),\n",
              " (')', 0.32062333822250366),\n",
              " ('–', 0.3132176995277405),\n",
              " ('cher', 0.24968355894088745),\n",
              " ('au', 0.2447778731584549),\n",
              " ('pardon', 0.238397479057312),\n",
              " ('tan', 0.23075149953365326),\n",
              " ('right', 0.22937126457691193)]"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rH8QzH7hIvRn"
      },
      "id": "rH8QzH7hIvRn",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "Копия блокнота \"EXAM_practical_part.ipynb\"",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}